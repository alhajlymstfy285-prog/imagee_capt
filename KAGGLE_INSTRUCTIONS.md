# ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Kaggle

## Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¨Ø§Ù„ØªÙØµÙŠÙ„

### 1ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„ÙƒÙˆØ¯ Ø¹Ù„Ù‰ GitHub

```bash
# ÙÙŠ terminal Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ
git init
git add .
git commit -m "Image captioning project"
git branch -M main
git remote add origin https://github.com/<username>/<repo-name>.git
git push -u origin main
```

### 2ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Notebook Ø¹Ù„Ù‰ Kaggle

1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ [Kaggle](https://www.kaggle.com)
2. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ **Code** â†’ **New Notebook**
3. Ù…Ù† Settings:
   - **Accelerator**: Ø§Ø®ØªØ± **GPU T4 x2** (Ù…Ø¬Ø§Ù†ÙŠ)
   - **Internet**: ÙØ¹Ù‘Ù„ **Internet On**
   - **Persistence**: Ø§Ø®ØªØ§Ø± **Files only**

### 3ï¸âƒ£ Ø¥Ø¶Ø§ÙØ© Dataset

1. Ø§Ø¶ØºØ· **Add Data** Ù…Ù† Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø£ÙŠÙ…Ù†
2. Ø§Ø¨Ø­Ø« Ø¹Ù†: **flickr-image-dataset**
3. Ø§Ø®ØªØ±: `hsankesara/flickr-image-dataset`
4. Ø§Ø¶ØºØ· **Add**

### 4ï¸âƒ£ ÙƒÙˆØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ Kaggle Notebook

```python
# Cell 1: Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ø±ÙŠØ¨Ùˆ
!git clone https://github.com/<your-username>/<your-repo>.git
%cd <your-repo>

# Cell 2: ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
!pip install -q -r requirements.txt

# Cell 3: ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Flickr
!python kaggle_setup.py

# Cell 4: ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
!python training/Vanilla_RNN.py

# Cell 5: Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
import json
with open('results/Vanilla_RNN/results.json', 'r') as f:
    results = json.load(f)
    
print(f"Final Train Loss: {results['final_train_loss']:.4f}")
print(f"Final Val Loss: {results['final_val_loss']:.4f}")
print(f"Best Val Loss: {results['best_val_loss']:.4f}")

# Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø®Ø³Ø§Ø±Ø©
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(results['train_loss_history'])
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.subplot(1, 2, 2)
plt.plot(results['val_loss_history'])
plt.title('Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.tight_layout()
plt.show()
```

### 5ï¸âƒ£ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©

```python
# LSTM
!python training/LSTM.py

# Attention LSTM
!python training/Attention_LSTM.py

# Transformer
!python training/Transformer.py
```

### 6ï¸âƒ£ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

```python
# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ output
!mkdir -p /kaggle/working/outputs
!cp -r results/* /kaggle/working/outputs/

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
# Ø³ÙŠÙƒÙˆÙ† Ù…ØªØ§Ø­ ÙÙŠ Output tab Ø¨Ø¹Ø¯ Ø§Ù„Ù€ commit
```

## âš™ï¸ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ØŒ Ø¹Ø¯Ù‘Ù„ Ù…Ù„Ù `configs/Vanilla_RNN.yaml`:

```yaml
model:
  wordvec_dim: 256      # Ø²ÙˆØ¯ Ù…Ù† 128
  hidden_dim: 512       # Ø²ÙˆØ¯ Ù…Ù† 128

training:
  num_epochs: 30        # Ù‚Ù„Ù„ Ù…Ù† 50
  batch_size: 32        # Ù‚Ù„Ù„ Ù…Ù† 64 Ù„Ùˆ ÙÙŠ memory issues
  learning_rate: 0.0005 # Ù‚Ù„Ù„ Ù…Ù† 0.001
  weight_decay: 0.0001  # Ø£Ø¶Ù regularization
```

## ğŸ› Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„

### Out of Memory
```python
# Ù‚Ù„Ù„ batch size ÙÙŠ config
batch_size: 16  # Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 64
```

### Dataset Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯
```python
# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±
import os
print(os.listdir('/kaggle/input'))
print(os.listdir('/kaggle/input/flickr-image-dataset'))
```

### Ø§Ù„ÙƒÙˆØ¯ Ù…Ø´ Ø´ØºØ§Ù„
```python
# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
!pip list | grep torch
!python --version
```

## ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬

Ø¨Ø¹Ø¯ ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:

```python
import json
import pandas as pd

models = ['Vanilla_RNN', 'LSTM', 'Attention_LSTM', 'Transformer']
results_list = []

for model in models:
    try:
        with open(f'results/{model}/results.json', 'r') as f:
            data = json.load(f)
            results_list.append({
                'Model': model,
                'Train Loss': data['final_train_loss'],
                'Val Loss': data['final_val_loss'],
                'Best Val Loss': data['best_val_loss'],
                'Parameters': data['num_params'],
                'Time (s)': data['total_time']
            })
    except:
        pass

df = pd.DataFrame(results_list)
print(df.to_string(index=False))
```

## ğŸ’¡ Ù†ØµØ§Ø¦Ø­

1. **Ø§Ø¨Ø¯Ø£ Ø¨Ù€ dataset ØµØºÙŠØ±** (max_samples=1000) Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
2. **Ø§Ø³ØªØ®Ø¯Ù… GPU** Ø¯Ø§ÙŠÙ…Ø§Ù‹ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
3. **Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù€ validation loss** Ù„ØªØ¬Ù†Ø¨ overfitting
4. **Ø§Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬** Ù‚Ø¨Ù„ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù€ notebook
5. **Ø§Ø³ØªØ®Ø¯Ù… early stopping** Ù„ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª

## ğŸ¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

1. Ø¬Ø±Ø¨ LSTM - Ø§Ù„Ù…ÙØ±ÙˆØ¶ ÙŠÙƒÙˆÙ† Ø£Ø­Ø³Ù† Ù…Ù† RNN
2. Ø¬Ø±Ø¨ Attention - Ø§Ù„Ù…ÙØ±ÙˆØ¶ ÙŠÙƒÙˆÙ† Ø£Ø­Ø³Ù† Ù…Ù† LSTM
3. Ù‚Ø§Ø±Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
4. Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ù€ hyperparameters
5. Ø¬Ø±Ø¨ augmentation Ù„Ù„ØµÙˆØ±
